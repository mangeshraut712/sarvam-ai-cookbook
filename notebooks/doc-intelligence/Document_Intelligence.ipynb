{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Document Intelligence API Tutorial**\n",
    "\n",
    "This notebook demonstrates how to use **Sarvam's Document Intelligence API** to extract structured, machine-readable data from documents. Powered by [Sarvam Vision](https://docs.sarvam.ai/api-reference-docs/getting-started/models/sarvam-vision), the API supports:\n",
    "\n",
    "- **High-fidelity text extraction** across 23 languages (22 Indian + English)\n",
    "- **Layout & structure preservation** including reading order and hierarchies\n",
    "- **Table parsing** into structured HTML or Markdown\n",
    "- **Multiple output formats** â€” HTML, Markdown, or JSON (delivered as ZIP)\n",
    "- **Batch processing** of multi-page documents and ZIP archives\n",
    "\n",
    "### Supported Input Formats\n",
    "\n",
    "| Format | Extension | Description |\n",
    "|--------|-----------|-------------|\n",
    "| PDF | `.pdf` | Multi-page PDF documents |\n",
    "| PNG | `.png` | Document page images |\n",
    "| JPEG | `.jpg`, `.jpeg` | Document page images |\n",
    "| ZIP | `.zip` | Flat archive containing document page images (JPG/PNG) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Installation**\n",
    "\n",
    "Install the Sarvam AI Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqq sarvamai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Setting Up the API Key**\n",
    "\n",
    "To use the Document Intelligence API, you need an API subscription key:\n",
    "\n",
    "1. **Obtain your API key**: Sign up on the [Sarvam AI Dashboard](https://dashboard.sarvam.ai/) to get one.\n",
    "2. **Replace the placeholder key**: In the code below, replace `\"YOUR_SARVAM_API_KEY\"` with your actual API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARVAM_API_KEY = \"YOUR_SARVAM_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Initialize the Client**\n",
    "\n",
    "Create a `SarvamAI` client instance with your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sarvamai import SarvamAI\n",
    "\n",
    "client = SarvamAI(api_subscription_key=SARVAM_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Understanding the Parameters**\n",
    "\n",
    "### Job Configuration\n",
    "\n",
    "| Parameter | Type | Description | Options |\n",
    "|-----------|------|-------------|---------|  \n",
    "| `language` | string | Target language in BCP-47 format | See supported languages below |\n",
    "| `output_format` | string | Output format for processed documents | `\"md\"` (Markdown, default), `\"html\"`, `\"json\"` |\n",
    "\n",
    "### Supported Languages (BCP-47 format)\n",
    "\n",
    "| Language | Code | Language | Code |\n",
    "|----------|------|----------|------|\n",
    "| Hindi | `hi-IN` | English | `en-IN` |\n",
    "| Bengali | `bn-IN` | Gujarati | `gu-IN` |\n",
    "| Kannada | `kn-IN` | Malayalam | `ml-IN` |\n",
    "| Marathi | `mr-IN` | Odia | `or-IN` |\n",
    "| Punjabi | `pa-IN` | Tamil | `ta-IN` |\n",
    "| Telugu | `te-IN` | Urdu | `ur-IN` |\n",
    "| Assamese | `as-IN` | Bodo | `bodo-IN` |\n",
    "| Dogri | `doi-IN` | Kashmiri | `ks-IN` |\n",
    "| Konkani | `kok-IN` | Maithili | `mai-IN` |\n",
    "| Manipuri | `mni-IN` | Nepali | `ne-IN` |\n",
    "| Sanskrit | `sa-IN` | Santali | `sat-IN` |\n",
    "| Sindhi | `sd-IN` | | |\n",
    "\n",
    "### Output Formats (delivered as ZIP file)\n",
    "\n",
    "| Format | Description |\n",
    "|--------|-------------|\n",
    "| `md` | Markdown files (default) |\n",
    "| `html` | Structured HTML files with layout preservation |\n",
    "| `json` | Structured JSON files for programmatic processing |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Process a Document**\n",
    "\n",
    "The Document Intelligence API uses an asynchronous job-based workflow:\n",
    "\n",
    "1. **Create a job** with your desired language and output format\n",
    "2. **Upload your document** (PDF, image, or ZIP archive)\n",
    "3. **Start the job** to begin processing\n",
    "4. **Wait for completion** and monitor progress\n",
    "5. **Download the output** (ZIP file with processed results)\n",
    "\n",
    "### 5.1 Upload a Document\n",
    "\n",
    "First, make sure you have a PDF or image file ready. You can upload it using the widget below (for Google Colab) or set the file path directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Set the path to your document directly\n",
    "document_path = \"document.pdf\"  # Replace with your document path\n",
    "\n",
    "# Option 2: Upload a file in Google Colab\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "# document_path = list(uploaded.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create a Job, Upload, and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a Document Intelligence job\n",
    "job = client.document_intelligence.create_job(\n",
    "    language=\"hi-IN\",       # Target language (BCP-47 format)\n",
    "    output_format=\"md\"      # Output format: \"html\", \"md\", or \"json\" (delivered as ZIP)\n",
    ")\n",
    "print(f\"Job created successfully!\")\n",
    "\n",
    "# Step 2: Upload your document\n",
    "job.upload_file(document_path)\n",
    "print(f\"Document uploaded: {document_path}\")\n",
    "\n",
    "# Step 3: Start processing\n",
    "job.start()\n",
    "print(\"Processing started...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Wait for Completion and Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Wait for completion\n",
    "status = job.wait_until_complete()\n",
    "print(f\"Job completed with state: {status.job_state}\")\n",
    "\n",
    "# Step 5: Get processing metrics\n",
    "metrics = job.get_page_metrics()\n",
    "print(f\"\\nProcessing Metrics:\")\n",
    "print(f\"  Total pages: {metrics['total_pages']}\")\n",
    "print(f\"  Pages processed: {metrics['pages_processed']}\")\n",
    "print(f\"  Pages succeeded: {metrics['pages_succeeded']}\")\n",
    "print(f\"  Pages failed: {metrics['pages_failed']}\")\n",
    "\n",
    "# Step 6: Download the output (ZIP file)\n",
    "output_path = \"./output.zip\"\n",
    "job.download_output(output_path)\n",
    "print(f\"\\nOutput saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Extract and View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Extract the ZIP file\n",
    "extract_dir = \"./doc_intelligence_output\"\n",
    "with zipfile.ZipFile(output_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "# List extracted files\n",
    "print(\"Extracted files:\")\n",
    "for root, dirs, files in os.walk(extract_dir):\n",
    "    for file in sorted(files):\n",
    "        filepath = os.path.join(root, file)\n",
    "        print(f\"  {filepath}\")\n",
    "\n",
    "# Display the content of the first output file\n",
    "output_files = []\n",
    "for root, dirs, files in os.walk(extract_dir):\n",
    "    for file in sorted(files):\n",
    "        output_files.append(os.path.join(root, file))\n",
    "\n",
    "if output_files:\n",
    "    print(f\"\\n--- Content of {output_files[0]} ---\\n\")\n",
    "    with open(output_files[0], 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "        print(content[:2000])  # Print first 2000 chars\n",
    "        if len(content) > 2000:\n",
    "            print(\"\\n... (truncated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Error Handling**\n",
    "\n",
    "Here's how to handle errors gracefully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sarvamai import SarvamAI\n",
    "from sarvamai.core.api_error import ApiError\n",
    "\n",
    "client = SarvamAI(api_subscription_key=SARVAM_API_KEY)\n",
    "\n",
    "try:\n",
    "    job = client.document_intelligence.create_job(\n",
    "        language=\"hi-IN\",\n",
    "        output_format=\"md\"\n",
    "    )\n",
    "    job.upload_file(\"document.pdf\")\n",
    "    job.start()\n",
    "    status = job.wait_until_complete()\n",
    "\n",
    "    if status.job_state == \"Completed\":\n",
    "        job.download_output(\"./output.zip\")\n",
    "        print(\"Output saved to ./output.zip\")\n",
    "    else:\n",
    "        print(f\"Job ended with state: {status.job_state}\")\n",
    "        print(f\"Details: {status}\")\n",
    "\n",
    "except ApiError as e:\n",
    "    if e.status_code == 400:\n",
    "        print(f\"Bad request: {e.body}\")\n",
    "    elif e.status_code == 403:\n",
    "        print(\"Invalid API key\")\n",
    "    elif e.status_code == 429:\n",
    "        print(\"Rate limit exceeded\")\n",
    "    else:\n",
    "        print(f\"Error {e.status_code}: {e.body}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Document file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Job States**\n",
    "\n",
    "| State | Description |\n",
    "|-------|-------------|\n",
    "| `Accepted` | Job created, awaiting file upload |\n",
    "| `Pending` | File uploaded, waiting to start |\n",
    "| `Running` | Processing in progress |\n",
    "| `Completed` | All pages processed successfully |\n",
    "| `PartiallyCompleted` | Some pages succeeded, some failed |\n",
    "| `Failed` | All pages failed or job-level error |\n",
    "\n",
    "## **8. Error Codes**\n",
    "\n",
    "| HTTP Status | Error Code | Description |\n",
    "|-------------|-----------|-------------|\n",
    "| `400` | `invalid_request_error` | Invalid parameters or missing required fields |\n",
    "| `403` | `invalid_api_key_error` | Invalid or missing API key |\n",
    "| `404` | `not_found_error` | Job not found |\n",
    "| `422` | `unprocessable_entity_error` | Invalid file format or corrupted file |\n",
    "| `429` | `insufficient_quota_error` | Rate limit or quota exceeded |\n",
    "| `500` | `internal_server_error` | Server error, retry the request |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Best Practices**\n",
    "\n",
    "- **Choose the right format**: Use Markdown for human-readable output and HTML for web rendering and rich formatting.\n",
    "- **Specify language**: Always specify the correct language code for optimal text extraction accuracy, especially for Indian languages.\n",
    "- **Handle large documents**: For large documents, monitor `page_metrics` to track progress and handle partial failures gracefully.\n",
    "- **Use HTML for tables**: Choose HTML output format when you need to preserve table structures and rich formatting.\n",
    "- **ZIP input**: For ZIP files, include only JPG and PNG document pages in a flat structure (no nested folders)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. Conclusion**\n",
    "\n",
    "This notebook demonstrated how to use **Sarvam's Document Intelligence API** to extract structured data from documents. The API provides:\n",
    "\n",
    "1. Enterprise-grade document processing powered by Sarvam Vision\n",
    "2. Support for 23 languages including all 22 Constitutionally recognized Indian languages\n",
    "3. Multiple output formats (Markdown, HTML, JSON)\n",
    "4. Job-based async processing with progress tracking\n",
    "\n",
    "---\n",
    "\n",
    "### **Additional Resources**\n",
    "\n",
    "- **Documentation**: [docs.sarvam.ai](https://docs.sarvam.ai)\n",
    "- **API Reference**: [Document Intelligence API](https://docs.sarvam.ai/api-reference-docs/document-intelligence)\n",
    "- **Sarvam Vision Model**: [Learn more](https://docs.sarvam.ai/api-reference-docs/getting-started/models/sarvam-vision)\n",
    "- **Community**: [Join the Discord Community](https://discord.gg/hTuVuPNF)\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Notes**\n",
    "\n",
    "- Keep your API key secure.\n",
    "- Specify the correct language for best results on Indian language documents.\n",
    "- Monitor page metrics for large documents to track progress.\n",
    "\n",
    "**Keep Building!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}