{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njEMu7DlvMUn"
   },
   "source": [
    "# **üìñ Batch Speech-to-Text (STT) API Demo Using Saarika Model**\n",
    "\n",
    "### **üîó Overview**\n",
    "\n",
    "This notebook demonstrates how to use Sarvam AI's **Batch Speech-to-Text (STT) API** for transcribing audio files at scale using the Sarvam AI SDK. You'll learn both **synchronous** and **asynchronous** usage patterns, understand key parameters, and see how to upload files, poll for job completion, and download results.\n",
    "\n",
    "### **Instructions to Keep in Mind Before Running the Notebook:**\n",
    "\n",
    "1. **Get the Subscription Key**:  \n",
    "   Go to [dashboard.sarvam.ai](https://dashboard.sarvam.ai) and copy your **API-Subscription Key**.\n",
    "\n",
    "2. **Upload Files**:  \n",
    "   Use the **Upload** button in the Jupyter notebook to upload the files (e.g., audio files) you want to process.\n",
    "\n",
    "3. **Set File Path**:  \n",
    "   Modify the file path in the code to match the path of your uploaded file, e.g., `file_path = '/path/to/your/file.wav'`.\n",
    "\n",
    "4. **Set Download Directory**:  \n",
    "   Change the directory path where you want the files to be saved after download, e.g., `destination_dir = './output'`.\n",
    "\n",
    "5. **Run the Code**:  \n",
    "   Execute the code with the correct **API key**, **file paths**, and **download directory**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ForbiddenError",
     "evalue": "headers: {'date': 'Tue, 09 Sep 2025 09:33:05 GMT', 'content-type': 'application/json', 'content-length': '36', 'connection': 'keep-alive', 'server': 'uvicorn', 'x-request-id': '20250909_64fa1c70-1664-4224-96d7-3e5073abae3a', 'access-control-allow-origin': '*', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload'}, status_code: 403, body: {'detail': 'Subscription not found.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mForbiddenError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 34\u001b[39m\n",
      "\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTranscription completed. Output saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Run the asynchronous example\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_stt_async_job()\n",
      "\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Optional: Get memory statistics for debugging\u001b[39;00m\n",
      "\u001b[32m     37\u001b[39m current, peak = tracemalloc.get_traced_memory()\n",
      "\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mrun_stt_async_job\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m      3\u001b[39m async_client = AsyncSarvamAI(api_subscription_key=SARVAM_API_KEY)\n",
      "\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Create a new job\u001b[39;00m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m job = \u001b[38;5;28;01mawait\u001b[39;00m async_client.speech_to_text_job.create_job(\n",
      "\u001b[32m      7\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33msaarika:v2.5\u001b[39m\u001b[33m\"\u001b[39m,\n",
      "\u001b[32m      8\u001b[39m     with_diarization=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[32m      9\u001b[39m     with_timestamps=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[32m     10\u001b[39m     language_code=\u001b[33m\"\u001b[39m\u001b[33men-IN\u001b[39m\u001b[33m\"\u001b[39m,\n",
      "\u001b[32m     11\u001b[39m     num_speakers=\u001b[32m2\u001b[39m,\n",
      "\u001b[32m     12\u001b[39m )\n",
      "\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJob created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob._job_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Upload files\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sarvam/devrel/sarvam-ai-cookbook/.venv/lib/python3.11/site-packages/sarvamai/speech_to_text_job/client.py:574\u001b[39m, in \u001b[36mAsyncSpeechToTextJobClient.create_job\u001b[39m\u001b[34m(self, model, with_diarization, with_timestamps, language_code, num_speakers, callback, request_options)\u001b[39m\n",
      "\u001b[32m    533\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_job\u001b[39m(\n",
      "\u001b[32m    534\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[32m    535\u001b[39m     model: SpeechToTextModel = \u001b[33m\"\u001b[39m\u001b[33msaarika:v2.5\u001b[39m\u001b[33m\"\u001b[39m,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m     request_options: typing.Optional[RequestOptions] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[32m    542\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mAsyncSpeechToTextJob\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[32m    543\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m    544\u001b[39m \u001b[33;03m    Create a new Speech-to-Text bulk job.\u001b[39;00m\n",
      "\u001b[32m    545\u001b[39m \n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    572\u001b[39m \u001b[33;03m        A handle to the newly created job.\u001b[39;00m\n",
      "\u001b[32m    573\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initialise(\n",
      "\u001b[32m    575\u001b[39m         job_parameters=SpeechToTextJobParametersParams(\n",
      "\u001b[32m    576\u001b[39m             language_code=language_code,\n",
      "\u001b[32m    577\u001b[39m             model=model,\n",
      "\u001b[32m    578\u001b[39m             with_diarization=with_diarization,\n",
      "\u001b[32m    579\u001b[39m             with_timestamps=with_timestamps,\n",
      "\u001b[32m    580\u001b[39m             num_speakers=num_speakers,  \u001b[38;5;66;03m# type: ignore[typeddict-item]\u001b[39;00m\n",
      "\u001b[32m    581\u001b[39m         ),\n",
      "\u001b[32m    582\u001b[39m         callback=callback,\n",
      "\u001b[32m    583\u001b[39m         request_options=request_options,\n",
      "\u001b[32m    584\u001b[39m     )\n",
      "\u001b[32m    585\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m AsyncSpeechToTextJob(job_id=response.job_id, client=\u001b[38;5;28mself\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sarvam/devrel/sarvam-ai-cookbook/.venv/lib/python3.11/site-packages/sarvamai/speech_to_text_job/client.py:352\u001b[39m, in \u001b[36mAsyncSpeechToTextJobClient.initialise\u001b[39m\u001b[34m(self, job_parameters, callback, request_options)\u001b[39m\n",
      "\u001b[32m    307\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minitialise\u001b[39m(\n",
      "\u001b[32m    308\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[32m    309\u001b[39m     *,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m     request_options: typing.Optional[RequestOptions] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[32m    313\u001b[39m ) -> BulkJobInitResponseV1:\n",
      "\u001b[32m    314\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m    315\u001b[39m \u001b[33;03m    Get a job uuid, and storage folder details for speech to text bulk job v1\u001b[39;00m\n",
      "\u001b[32m    316\u001b[39m \n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n",
      "\u001b[32m    351\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     _response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raw_client.initialise(\n",
      "\u001b[32m    353\u001b[39m         job_parameters=job_parameters, callback=callback, request_options=request_options\n",
      "\u001b[32m    354\u001b[39m     )\n",
      "\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response.data\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sarvam/devrel/sarvam-ai-cookbook/.venv/lib/python3.11/site-packages/sarvamai/speech_to_text_job/raw_client.py:681\u001b[39m, in \u001b[36mAsyncRawSpeechToTextJobClient.initialise\u001b[39m\u001b[34m(self, job_parameters, callback, request_options)\u001b[39m\n",
      "\u001b[32m    670\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n",
      "\u001b[32m    671\u001b[39m         headers=\u001b[38;5;28mdict\u001b[39m(_response.headers),\n",
      "\u001b[32m    672\u001b[39m         body=typing.cast(\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    678\u001b[39m         ),\n",
      "\u001b[32m    679\u001b[39m     )\n",
      "\u001b[32m    680\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _response.status_code == \u001b[32m403\u001b[39m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ForbiddenError(\n",
      "\u001b[32m    682\u001b[39m         headers=\u001b[38;5;28mdict\u001b[39m(_response.headers),\n",
      "\u001b[32m    683\u001b[39m         body=typing.cast(\n",
      "\u001b[32m    684\u001b[39m             typing.Optional[typing.Any],\n",
      "\u001b[32m    685\u001b[39m             parse_obj_as(\n",
      "\u001b[32m    686\u001b[39m                 type_=typing.Optional[typing.Any],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[32m    687\u001b[39m                 object_=_response.json(),\n",
      "\u001b[32m    688\u001b[39m             ),\n",
      "\u001b[32m    689\u001b[39m         ),\n",
      "\u001b[32m    690\u001b[39m     )\n",
      "\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _response.status_code == \u001b[32m422\u001b[39m:\n",
      "\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnprocessableEntityError(\n",
      "\u001b[32m    693\u001b[39m         headers=\u001b[38;5;28mdict\u001b[39m(_response.headers),\n",
      "\u001b[32m    694\u001b[39m         body=typing.cast(\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    700\u001b[39m         ),\n",
      "\u001b[32m    701\u001b[39m     )\n",
      "\n",
      "\u001b[31mForbiddenError\u001b[39m: headers: {'date': 'Tue, 09 Sep 2025 09:33:05 GMT', 'content-type': 'application/json', 'content-length': '36', 'connection': 'keep-alive', 'server': 'uvicorn', 'x-request-id': '20250909_64fa1c70-1664-4224-96d7-3e5073abae3a', 'access-control-allow-origin': '*', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload'}, status_code: 403, body: {'detail': 'Subscription not found.'}"
     ]
    }
   ],
   "source": [
    "async def run_stt_async_job():\n",
    "    # Initialize async client\n",
    "    async_client = AsyncSarvamAI(api_subscription_key=SARVAM_API_KEY)\n",
    "\n",
    "    # Create a new job\n",
    "    job = await async_client.speech_to_text_job.create_job(\n",
    "        model=\"saarika:v2.5\",\n",
    "        with_diarization=True,\n",
    "        with_timestamps=True,\n",
    "        language_code=\"en-IN\",\n",
    "        num_speakers=2,\n",
    "    )\n",
    "    print(f\"Job created: {job._job_id}\")\n",
    "\n",
    "    # Upload files\n",
    "    await job.upload_files(file_paths=audio_files, timeout=120.0)\n",
    "\n",
    "    # Start the job\n",
    "    await job.start()\n",
    "    print(\"Transcription started...\")\n",
    "\n",
    "    # Wait for completion\n",
    "    await job.wait_until_complete(poll_interval=5, timeout=600)\n",
    "\n",
    "    # Check if job failed\n",
    "    if job.is_failed():\n",
    "        raise RuntimeError(\"Transcription failed\")\n",
    "\n",
    "    # Download results\n",
    "    await job.download_outputs(output_dir=str(output_dir))\n",
    "    print(f\"Transcription completed. Output saved to: {output_dir}\")\n",
    "\n",
    "\n",
    "# Run the asynchronous example\n",
    "await run_stt_async_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **üìù Note:**\n",
    "\n",
    "The Batch API currently supports audio files with a duration of up to 10 minutes. If you have a longer file, you can split it into chunks of 10 minutes each. We provide code examples for file splitting at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_R6WPZGv5_2_"
   },
   "source": [
    "## **1. Installation**\n",
    "\n",
    "Before you begin, ensure you have the necessary Python libraries installed. Run the following commands to install the required packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJvMhkZ6vPTb"
   },
   "source": [
    "!pip install sarvamai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fr1wkbGUvHyH",
    "outputId": "7038207b-7f5c-4cee-93bd-d1fb47e972d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-storage-file-datalake\n",
      "  Downloading azure_storage_file_datalake-12.18.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (3.11.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
      "Collecting azure-core>=1.30.0 (from azure-storage-file-datalake)\n",
      "  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting azure-storage-blob>=12.24.1 (from azure-storage-file-datalake)\n",
      "  Downloading azure_storage_blob-12.24.1-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from azure-storage-file-datalake) (4.12.2)\n",
      "Collecting isodate>=0.6.1 (from azure-storage-file-datalake)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.30.0->azure-storage-file-datalake) (1.17.0)\n",
      "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.11/dist-packages (from azure-storage-blob>=12.24.1->azure-storage-file-datalake) (43.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12.24.1->azure-storage-file-datalake) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12.24.1->azure-storage-file-datalake) (2.22)\n",
      "Downloading azure_storage_file_datalake-12.18.1-py3-none-any.whl (258 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m258.3/258.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_storage_blob-12.24.1-py3-none-any.whl (408 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: isodate, aiofiles, azure-core, azure-storage-blob, azure-storage-file-datalake\n",
      "Successfully installed aiofiles-24.1.0 azure-core-1.32.0 azure-storage-blob-12.24.1 azure-storage-file-datalake-12.18.1 isodate-0.7.2\n"
     ]
    }
   ],
   "source": [
    "from sarvamai import SarvamAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6AO6tIgvVIc"
   },
   "source": [
    "## **2. Authentication**\n",
    "\n",
    "To use the API, you need an API subscription key. Follow these steps to set up your API key:\n",
    "\n",
    "1. **Obtain your API key**: If you don't have an API key, sign up on the [Sarvam AI Dashboard](https://dashboard.sarvam.ai/) to get one.\n",
    "2. **Replace the placeholder key**: In the code below, replace \"YOUR_SARVAM_AI_API_KEY\" with your actual API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFILCZmMvcjm"
   },
   "outputs": [],
   "source": [
    "SARVAM_API_KEY = \"YOUR_SARVAM_AI_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkjNgOTmvgZP"
   },
   "source": [
    "## **3. Understanding the Parameters**\n",
    "\n",
    "üîπ The Batch STT API takes several key parameters:\n",
    "\n",
    "### **Job Parameters**\n",
    "Sets up the job configuration for the STT batch process.\n",
    "\n",
    "**Parameters:**\n",
    "- `language_code`: Language code of input audio (e.g., `\"en-IN\"` for Indian English)\n",
    "- `model`: Transcription model (e.g., `\"saarika:v2.5\"` for latest general-purpose STT)\n",
    "- `with_timestamps`: If `True`, includes chunk-level timestamps\n",
    "- `with_diarization`: If `True`, enables speaker diarization\n",
    "- `num_speakers`: Number of speakers (used with diarization)\n",
    "\n",
    "### **File Upload**\n",
    "Handles uploading audio files for transcription.\n",
    "\n",
    "**Parameters:**\n",
    "- `file_paths`: List of paths to audio files to upload\n",
    "- `timeout`: Max time (seconds) to wait for upload (default: 60.0)\n",
    "\n",
    "### **wait_until_complete**\n",
    "Controls polling and waiting for the STT job to finish.\n",
    "\n",
    "**Parameters:**\n",
    "- `poll_interval`: How frequently the job status is checked for completion, in seconds (default: `5`).\n",
    "- `timeout`: Maximum time to wait for the job to complete, in seconds (default: `600`). If the job doesn't finish within this time, it will raise a timeout error.\n",
    "\n",
    "**Note:** Even if a timeout error is raised, the job might still be running in the background. You can continue polling the job status later using the job ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yGItkUpvtr7"
   },
   "outputs": [],
   "source": [
    "## **4. Synchronous STT Batch Example**\n",
    "\n",
    "### **4.1 Initialize the Client**\n",
    "\n",
    "Create a Sarvam client instance using your API key. This client will be used to interact with the Batch STT API.\n",
    "    def __init__(self, url: str):\n",
    "        self.account_url, self.file_system_name, self.directory_name, self.sas_token = (\n",
    "            self._extract_url_components(url)\n",
    "        )\n",
    "        self.lock = asyncio.Lock()\n",
    "        print(f\"Initialized SarvamClient with directory: {self.directory_name}\")\n",
    "\n",
    "    def update_url(self, url: str):\n",
    "        self.account_url, self.file_system_name, self.directory_name, self.sas_token = (\n",
    "            self._extract_url_components(url)\n",
    "        )\n",
    "        print(f\"Updated URL to directory: {self.directory_name}\")\n",
    "\n",
    "    def _extract_url_components(self, url: str):\n",
    "        parsed_url = urlparse(url)\n",
    "        account_url = f\"{parsed_url.scheme}://{parsed_url.netloc}\".replace(\n",
    "            \".blob.\", \".dfs.\"\n",
    "        )\n",
    "        path_components = parsed_url.path.strip(\"/\").split(\"/\")\n",
    "        file_system_name = path_components[0]\n",
    "        directory_name = \"/\".join(path_components[1:])\n",
    "        sas_token = parsed_url.query\n",
    "        return account_url, file_system_name, directory_name, sas_token\n",
    "\n",
    "    async def upload_files(self, local_file_paths, overwrite=True):\n",
    "        print(f\"Starting upload of {len(local_file_paths)} files\")\n",
    "        async with DataLakeDirectoryClient(\n",
    "            account_url=f\"{self.account_url}?{self.sas_token}\",\n",
    "            file_system_name=self.file_system_name,\n",
    "            directory_name=self.directory_name,\n",
    "            credential=None,\n",
    "        ) as directory_client:\n",
    "            tasks = []\n",
    "            for path in local_file_paths:\n",
    "                file_name = path.split(\"/\")[-1]\n",
    "                tasks.append(\n",
    "                    self._upload_file(directory_client, path, file_name, overwrite)\n",
    "                )\n",
    "            results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            print(\n",
    "                f\"Upload completed for {sum(1 for r in results if not isinstance(r, Exception))} files\"\n",
    "            )\n",
    "\n",
    "    async def _upload_file(\n",
    "        self, directory_client, local_file_path, file_name, overwrite=True\n",
    "    ):\n",
    "        try:\n",
    "            async with aiofiles.open(local_file_path, mode=\"rb\") as file_data:\n",
    "                mime_type = mimetypes.guess_type(local_file_path)[0] or \"audio/wav\"\n",
    "                file_client = directory_client.get_file_client(file_name)\n",
    "                data = await file_data.read()\n",
    "                await file_client.upload_data(\n",
    "                    data,\n",
    "                    overwrite=overwrite,\n",
    "                    content_settings=ContentSettings(content_type=mime_type),\n",
    "                )\n",
    "                print(f\"‚úÖ File uploaded successfully: {file_name}\")\n",
    "                print(f\"   Type: {mime_type}\")\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Upload failed for {file_name}: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    async def list_files(self):\n",
    "        print(\"\\nüìÇ Listing files in directory...\")\n",
    "        file_names = []\n",
    "        async with FileSystemClient(\n",
    "            account_url=f\"{self.account_url}?{self.sas_token}\",\n",
    "            file_system_name=self.file_system_name,\n",
    "            credential=None,\n",
    "        ) as file_system_client:\n",
    "            async for path in file_system_client.get_paths(self.directory_name):\n",
    "                file_name = path.name.split(\"/\")[-1]\n",
    "                async with self.lock:\n",
    "                    file_names.append(file_name)\n",
    "        print(f\"Found {len(file_names)} files:\")\n",
    "        for file in file_names:\n",
    "            print(f\"   üìÑ {file}\")\n",
    "        return file_names\n",
    "\n",
    "    async def download_files(self, file_names, destination_dir):\n",
    "        print(f\"\\n‚¨áÔ∏è Starting download of {len(file_names)} files to {destination_dir}\")\n",
    "        async with DataLakeDirectoryClient(\n",
    "            account_url=f\"{self.account_url}?{self.sas_token}\",\n",
    "            file_system_name=self.file_system_name,\n",
    "            directory_name=self.directory_name,\n",
    "            credential=None,\n",
    "        ) as directory_client:\n",
    "            tasks = []\n",
    "            for file_name in file_names:\n",
    "                tasks.append(\n",
    "                    self._download_file(directory_client, file_name, destination_dir)\n",
    "                )\n",
    "            results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "            print(\n",
    "                f\"Download completed for {sum(1 for r in results if not isinstance(r, Exception))} files\"\n",
    "            )\n",
    "\n",
    "    async def _download_file(self, directory_client, file_name, destination_dir):\n",
    "        try:\n",
    "            file_client = directory_client.get_file_client(file_name)\n",
    "            download_path = f\"{destination_dir}/{file_name}\"\n",
    "            async with aiofiles.open(download_path, mode=\"wb\") as file_data:\n",
    "                stream = await file_client.download_file()\n",
    "                data = await stream.readall()\n",
    "                await file_data.write(data)\n",
    "            print(f\"‚úÖ Downloaded: {file_name} -> {download_path}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Download failed for {file_name}: {str(e)}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ForbiddenError",
     "evalue": "headers: {'date': 'Tue, 09 Sep 2025 09:33:05 GMT', 'content-type': 'application/json', 'content-length': '36', 'connection': 'keep-alive', 'server': 'uvicorn', 'x-request-id': '20250909_64fa1c70-1664-4224-96d7-3e5073abae3a', 'access-control-allow-origin': '*', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload'}, status_code: 403, body: {'detail': 'Subscription not found.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mForbiddenError\u001b[39m                            Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 34\u001b[39m\n",
      "\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTranscription completed. Output saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Run the asynchronous example\u001b[39;00m\n",
      "\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_stt_async_job()\n",
      "\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Optional: Get memory statistics for debugging\u001b[39;00m\n",
      "\u001b[32m     37\u001b[39m current, peak = tracemalloc.get_traced_memory()\n",
      "\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mrun_stt_async_job\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[32m      3\u001b[39m async_client = AsyncSarvamAI(api_subscription_key=SARVAM_API_KEY)\n",
      "\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Create a new job\u001b[39;00m\n",
      "\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m job = \u001b[38;5;28;01mawait\u001b[39;00m async_client.speech_to_text_job.create_job(\n",
      "\u001b[32m      7\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33msaarika:v2.5\u001b[39m\u001b[33m\"\u001b[39m,\n",
      "\u001b[32m      8\u001b[39m     with_diarization=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[32m      9\u001b[39m     with_timestamps=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "\u001b[32m     10\u001b[39m     language_code=\u001b[33m\"\u001b[39m\u001b[33men-IN\u001b[39m\u001b[33m\"\u001b[39m,\n",
      "\u001b[32m     11\u001b[39m     num_speakers=\u001b[32m2\u001b[39m,\n",
      "\u001b[32m     12\u001b[39m )\n",
      "\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJob created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob._job_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Upload files\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sarvam/devrel/sarvam-ai-cookbook/.venv/lib/python3.11/site-packages/sarvamai/speech_to_text_job/client.py:574\u001b[39m, in \u001b[36mAsyncSpeechToTextJobClient.create_job\u001b[39m\u001b[34m(self, model, with_diarization, with_timestamps, language_code, num_speakers, callback, request_options)\u001b[39m\n",
      "\u001b[32m    533\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_job\u001b[39m(\n",
      "\u001b[32m    534\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[32m    535\u001b[39m     model: SpeechToTextModel = \u001b[33m\"\u001b[39m\u001b[33msaarika:v2.5\u001b[39m\u001b[33m\"\u001b[39m,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    541\u001b[39m     request_options: typing.Optional[RequestOptions] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[32m    542\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mAsyncSpeechToTextJob\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[32m    543\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m    544\u001b[39m \u001b[33;03m    Create a new Speech-to-Text bulk job.\u001b[39;00m\n",
      "\u001b[32m    545\u001b[39m \n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    572\u001b[39m \u001b[33;03m        A handle to the newly created job.\u001b[39;00m\n",
      "\u001b[32m    573\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initialise(\n",
      "\u001b[32m    575\u001b[39m         job_parameters=SpeechToTextJobParametersParams(\n",
      "\u001b[32m    576\u001b[39m             language_code=language_code,\n",
      "\u001b[32m    577\u001b[39m             model=model,\n",
      "\u001b[32m    578\u001b[39m             with_diarization=with_diarization,\n",
      "\u001b[32m    579\u001b[39m             with_timestamps=with_timestamps,\n",
      "\u001b[32m    580\u001b[39m             num_speakers=num_speakers,  \u001b[38;5;66;03m# type: ignore[typeddict-item]\u001b[39;00m\n",
      "\u001b[32m    581\u001b[39m         ),\n",
      "\u001b[32m    582\u001b[39m         callback=callback,\n",
      "\u001b[32m    583\u001b[39m         request_options=request_options,\n",
      "\u001b[32m    584\u001b[39m     )\n",
      "\u001b[32m    585\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m AsyncSpeechToTextJob(job_id=response.job_id, client=\u001b[38;5;28mself\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sarvam/devrel/sarvam-ai-cookbook/.venv/lib/python3.11/site-packages/sarvamai/speech_to_text_job/client.py:352\u001b[39m, in \u001b[36mAsyncSpeechToTextJobClient.initialise\u001b[39m\u001b[34m(self, job_parameters, callback, request_options)\u001b[39m\n",
      "\u001b[32m    307\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minitialise\u001b[39m(\n",
      "\u001b[32m    308\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[32m    309\u001b[39m     *,\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m     request_options: typing.Optional[RequestOptions] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[32m    313\u001b[39m ) -> BulkJobInitResponseV1:\n",
      "\u001b[32m    314\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[32m    315\u001b[39m \u001b[33;03m    Get a job uuid, and storage folder details for speech to text bulk job v1\u001b[39;00m\n",
      "\u001b[32m    316\u001b[39m \n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n",
      "\u001b[32m    351\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     _response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raw_client.initialise(\n",
      "\u001b[32m    353\u001b[39m         job_parameters=job_parameters, callback=callback, request_options=request_options\n",
      "\u001b[32m    354\u001b[39m     )\n",
      "\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response.data\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/sarvam/devrel/sarvam-ai-cookbook/.venv/lib/python3.11/site-packages/sarvamai/speech_to_text_job/raw_client.py:681\u001b[39m, in \u001b[36mAsyncRawSpeechToTextJobClient.initialise\u001b[39m\u001b[34m(self, job_parameters, callback, request_options)\u001b[39m\n",
      "\u001b[32m    670\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(\n",
      "\u001b[32m    671\u001b[39m         headers=\u001b[38;5;28mdict\u001b[39m(_response.headers),\n",
      "\u001b[32m    672\u001b[39m         body=typing.cast(\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    678\u001b[39m         ),\n",
      "\u001b[32m    679\u001b[39m     )\n",
      "\u001b[32m    680\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _response.status_code == \u001b[32m403\u001b[39m:\n",
      "\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ForbiddenError(\n",
      "\u001b[32m    682\u001b[39m         headers=\u001b[38;5;28mdict\u001b[39m(_response.headers),\n",
      "\u001b[32m    683\u001b[39m         body=typing.cast(\n",
      "\u001b[32m    684\u001b[39m             typing.Optional[typing.Any],\n",
      "\u001b[32m    685\u001b[39m             parse_obj_as(\n",
      "\u001b[32m    686\u001b[39m                 type_=typing.Optional[typing.Any],  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[32m    687\u001b[39m                 object_=_response.json(),\n",
      "\u001b[32m    688\u001b[39m             ),\n",
      "\u001b[32m    689\u001b[39m         ),\n",
      "\u001b[32m    690\u001b[39m     )\n",
      "\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _response.status_code == \u001b[32m422\u001b[39m:\n",
      "\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UnprocessableEntityError(\n",
      "\u001b[32m    693\u001b[39m         headers=\u001b[38;5;28mdict\u001b[39m(_response.headers),\n",
      "\u001b[32m    694\u001b[39m         body=typing.cast(\n",
      "\u001b[32m   (...)\u001b[39m\u001b[32m    700\u001b[39m         ),\n",
      "\u001b[32m    701\u001b[39m     )\n",
      "\n",
      "\u001b[31mForbiddenError\u001b[39m: headers: {'date': 'Tue, 09 Sep 2025 09:33:05 GMT', 'content-type': 'application/json', 'content-length': '36', 'connection': 'keep-alive', 'server': 'uvicorn', 'x-request-id': '20250909_64fa1c70-1664-4224-96d7-3e5073abae3a', 'access-control-allow-origin': '*', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload'}, status_code: 403, body: {'detail': 'Subscription not found.'}"
     ]
    }
   ],
   "source": [
    "async def run_stt_async_job():\n",
    "    # Initialize async client\n",
    "    async_client = AsyncSarvamAI(api_subscription_key=SARVAM_API_KEY)\n",
    "\n",
    "    # Create a new job\n",
    "    job = await async_client.speech_to_text_job.create_job(\n",
    "        model=\"saarika:v2.5\",\n",
    "        with_diarization=True,\n",
    "        with_timestamps=True,\n",
    "        language_code=\"en-IN\",\n",
    "        num_speakers=2,\n",
    "    )\n",
    "    print(f\"Job created: {job._job_id}\")\n",
    "\n",
    "    # Upload files\n",
    "    await job.upload_files(file_paths=audio_files, timeout=120.0)\n",
    "\n",
    "    # Start the job\n",
    "    await job.start()\n",
    "    print(\"Transcription started...\")\n",
    "\n",
    "    # Wait for completion\n",
    "    await job.wait_until_complete(poll_interval=5, timeout=600)\n",
    "\n",
    "    # Check if job failed\n",
    "    if job.is_failed():\n",
    "        raise RuntimeError(\"Transcription failed\")\n",
    "\n",
    "    # Download results\n",
    "    await job.download_outputs(output_dir=str(output_dir))\n",
    "    print(f\"Transcription completed. Output saved to: {output_dir}\")\n",
    "\n",
    "\n",
    "# Run the asynchronous example\n",
    "await run_stt_async_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "id2zfGrHv--l"
   },
   "source": [
    "## 3. Sarvam AI API Integration\n",
    "\n",
    "These functions handle the Speech-to-Text job lifecycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3FxvpEMTwA5P"
   },
   "outputs": [],
   "source": [
    "async def initialize_job():\n",
    "    print(\"\\\\nüöÄ Initializing job...\")\n",
    "    url = \"https://api.sarvam.ai/speech-to-text/job/init\"\n",
    "    headers = {\"API-Subscription-Key\": API_SUBSCRIPTION_KEY}\n",
    "    response = requests.post(url, headers=headers)\n",
    "    print(\"\\\\nInitialize Job Response:\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(\"Response Body:\")\n",
    "    pprint(response.json() if response.status_code == 202 else response.text)\n",
    "\n",
    "    if response.status_code == 202:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "\n",
    "async def check_job_status(job_id):\n",
    "    print(f\"\\\\nüîç Checking status for job: {job_id}\")\n",
    "    url = f\"https://api.sarvam.ai/speech-to-text/job/{job_id}/status\"\n",
    "    headers = {\"API-Subscription-Key\": API_SUBSCRIPTION_KEY}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    print(\"\\\\nJob Status Response:\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(\"Response Body:\")\n",
    "    pprint(response.json() if response.status_code == 200 else response.text)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "\n",
    "async def start_job(job_id, language_code=LANGUAGE_CODE):\n",
    "    print(f\"\\\\n‚ñ∂Ô∏è Starting job: {job_id}\")\n",
    "    url = \"https://api.sarvam.ai/speech-to-text/job\"\n",
    "    headers = {\n",
    "        \"API-Subscription-Key\": API_SUBSCRIPTION_KEY,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    data = {\"job_id\": job_id, \"job_parameters\": {\"language_code\": language_code}}\n",
    "    print(\"\\\\nRequest Body:\")\n",
    "    pprint(data)\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    print(\"\\\\nStart Job Response:\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(\"Response Body:\")\n",
    "    pprint(response.json() if response.status_code == 200 else response.text)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAC7-sUgwEYw"
   },
   "source": [
    "## 4. Main Execution Flow\n",
    "\n",
    "Here's the main function that orchestrates the entire process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqagsZaMwE7B",
    "outputId": "f565fe45-dc3f-463a-c74d-c45a897c19dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n=== Starting Speech-to-Text Processing ===\n",
      "\\nüöÄ Initializing job...\n",
      "\\nInitialize Job Response:\n",
      "Status Code: 202\n",
      "Response Body:\n",
      "{'input_storage_path': 'https://appsprodbulkjobssa.blob.core.windows.net/bulk-upload-storage/jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/inputs?se=2025-02-20T07%3A10%3A17Z&sp=wdl&sv=2025-01-05&sr=d&sdd=5&sig=65mwac7JU9nfZf98Nve27s9UMD1Y17woiMip3FU%2BZB0%3D',\n",
      " 'job_id': '20250220_9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3',\n",
      " 'output_storage_path': 'https://appsprodbulkjobssa.blob.core.windows.net/bulk-upload-storage/jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/outputs?se=2025-02-27T06%3A10%3A17Z&sp=rl&sv=2025-01-05&sr=d&sdd=5&sig=l0T5G2hCtaQLkqUZSFhtMwr/Fmmgz2fUwcoa9o4Wukg%3D',\n",
      " 'storage_container_type': 'Azure'}\n",
      "\\nüì§ Uploading files to input storage: https://appsprodbulkjobssa.blob.core.windows.net/bulk-upload-storage/jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/inputs?se=2025-02-20T07%3A10%3A17Z&sp=wdl&sv=2025-01-05&sr=d&sdd=5&sig=65mwac7JU9nfZf98Nve27s9UMD1Y17woiMip3FU%2BZB0%3D\n",
      "Initialized SarvamClient with directory: jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/inputs\n",
      "Files to upload: ['arjun-kannada.wav']\n",
      "Starting upload of 1 files\n",
      "‚úÖ File uploaded successfully: arjun-kannada.wav\n",
      "   Type: audio/x-wav\n",
      "Upload completed for 1 files\n",
      "\\n‚ñ∂Ô∏è Starting job: 20250220_9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3\n",
      "\\nRequest Body:\n",
      "{'job_id': '20250220_9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3',\n",
      " 'job_parameters': {'language_code': 'bn-IN'}}\n",
      "\\nStart Job Response:\n",
      "Status Code: 200\n",
      "Response Body:\n",
      "{'job_status': {'created_at': '2025-02-20T06:10:17.678952+00:00',\n",
      "                'error_message': '',\n",
      "                'failed_files_count': 0,\n",
      "                'input_storage_path': 'https://appsprodbulkjobssa.blob.core.windows.net/bulk-upload-storage/jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/inputs?se=2025-02-20T07%3A10%3A17Z&sp=wdl&sv=2025-01-05&sr=d&sdd=5&sig=65mwac7JU9nfZf98Nve27s9UMD1Y17woiMip3FU%2BZB0%3D',\n",
      "                'job_details': [],\n",
      "                'job_id': '20250220_9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3',\n",
      "                'job_state': 'Pending',\n",
      "                'output_storage_path': 'https://appsprodbulkjobssa.blob.core.windows.net/bulk-upload-storage/jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/outputs?se=2025-02-27T06%3A10%3A17Z&sp=rl&sv=2025-01-05&sr=d&sdd=5&sig=l0T5G2hCtaQLkqUZSFhtMwr/Fmmgz2fUwcoa9o4Wukg%3D',\n",
      "                'owner_id': 'ba3a72b2144ea99c97e390e5f0f43780c693171b6fd7f68ad7dde2f62dcb801a',\n",
      "                'storage_container_type': 'Azure',\n",
      "                'successful_files_count': 0,\n",
      "                'total_files': 0,\n",
      "                'updated_at': '2025-02-20T06:10:20.462421+00:00'}}\n",
      "\\n‚è≥ Monitoring job status...\n",
      "\\nStatus check attempt 1\n",
      "\\nüîç Checking status for job: 20250220_9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3\n",
      "\\nJob Status Response:\n",
      "Status Code: 200\n",
      "Response Body:\n",
      "{'created_at': '2025-02-20T06:10:17.678952+00:00',\n",
      " 'error_message': '',\n",
      " 'failed_files_count': 0,\n",
      " 'input_storage_path': 'https://appsprodbulkjobssa.blob.core.windows.net/bulk-upload-storage/jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/inputs?se=2025-02-20T07%3A10%3A17Z&sp=wdl&sv=2025-01-05&sr=d&sdd=5&sig=65mwac7JU9nfZf98Nve27s9UMD1Y17woiMip3FU%2BZB0%3D',\n",
      " 'job_details': [],\n",
      " 'job_id': '20250220_9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3',\n",
      " 'job_state': 'Running',\n",
      " 'output_storage_path': 'https://appsprodbulkjobssa.blob.core.windows.net/bulk-upload-storage/jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/outputs?se=2025-02-27T06%3A10%3A17Z&sp=rl&sv=2025-01-05&sr=d&sdd=5&sig=l0T5G2hCtaQLkqUZSFhtMwr/Fmmgz2fUwcoa9o4Wukg%3D',\n",
      " 'owner_id': 'ba3a72b2144ea99c97e390e5f0f43780c693171b6fd7f68ad7dde2f62dcb801a',\n",
      " 'storage_container_type': 'Azure',\n",
      " 'successful_files_count': 0,\n",
      " 'total_files': 0,\n",
      " 'updated_at': '2025-02-20T06:10:21.154303+00:00'}\n",
      "‚è≥ Current status: Running\n",
      "\\nStatus check attempt 2\n",
      "\\nüîç Checking status for job: 20250220_9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3\n",
      "\\nJob Status Response:\n",
      "Status Code: 200\n",
      "Response Body:\n",
      "{'created_at': '2025-02-20T06:10:17.678952+00:00',\n",
      " 'error_message': '',\n",
      " 'failed_files_count': 0,\n",
      " 'input_storage_path': 'https://appsprodbulkjobssa.blob.core.windows.net/bulk-upload-storage/jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/inputs?se=2025-02-20T07%3A10%3A17Z&sp=wdl&sv=2025-01-05&sr=d&sdd=5&sig=65mwac7JU9nfZf98Nve27s9UMD1Y17woiMip3FU%2BZB0%3D',\n",
      " 'job_details': [{'error_message': '',\n",
      "                  'file_id': '0',\n",
      "                  'file_name': 'arjun-kannada.wav',\n",
      "                  'state': 'Success'}],\n",
      " 'job_id': '20250220_9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3',\n",
      " 'job_state': 'Completed',\n",
      " 'output_storage_path': 'https://appsprodbulkjobssa.blob.core.windows.net/bulk-upload-storage/jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/outputs?se=2025-02-27T06%3A10%3A17Z&sp=rl&sv=2025-01-05&sr=d&sdd=5&sig=l0T5G2hCtaQLkqUZSFhtMwr/Fmmgz2fUwcoa9o4Wukg%3D',\n",
      " 'owner_id': 'ba3a72b2144ea99c97e390e5f0f43780c693171b6fd7f68ad7dde2f62dcb801a',\n",
      " 'storage_container_type': 'Azure',\n",
      " 'successful_files_count': 1,\n",
      " 'total_files': 1,\n",
      " 'updated_at': '2025-02-20T06:10:22.193238+00:00'}\n",
      "‚úÖ Job completed successfully!\n",
      "\n",
      "üì• Downloading results from: https://appsprodbulkjobssa.blob.core.windows.net/bulk-upload-storage/jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/outputs?se=2025-02-27T06%3A10%3A17Z&sp=rl&sv=2025-01-05&sr=d&sdd=5&sig=l0T5G2hCtaQLkqUZSFhtMwr/Fmmgz2fUwcoa9o4Wukg%3D\n",
      "Updated URL to directory: jobs/2025-02-20/SPEECH_TO_TEXT_BULK/9fb0faff-fec4-4d6b-ad74-5b67b0dbf0b3/outputs\n",
      "\n",
      "üìÇ Listing files in directory...\n",
      "Found 1 files:\n",
      "   üìÑ 0.json\n",
      "\n",
      "‚¨áÔ∏è Starting download of 1 files to /Users/vinayakgavariya/Downloads/\n",
      "‚úÖ Downloaded: 0.json -> /Users/vinayakgavariya/Downloads//0.json\n",
      "Download completed for 1 files\n",
      "Files have been downloaded to: /Users/vinayakgavariya/Downloads/\n",
      "\\n=== Processing Complete ===\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    print(\"\\\\n=== Starting Speech-to-Text Processing ===\")\n",
    "\n",
    "    # Step 1: Initialize the job\n",
    "    job_info = await initialize_job()\n",
    "    if not job_info:\n",
    "        print(\"‚ùå Job initialization failed\")\n",
    "        return\n",
    "\n",
    "    job_id = job_info[\"job_id\"]\n",
    "    input_storage_path = job_info[\"input_storage_path\"]\n",
    "    output_storage_path = job_info[\"output_storage_path\"]\n",
    "\n",
    "    # Step 2: Upload files\n",
    "    print(f\"\\\\nüì§ Uploading files to input storage: {input_storage_path}\")\n",
    "    client = SarvamClient(input_storage_path)\n",
    "    local_files = [\"arjun-kannada.wav\"]  # Replace with your audio files\n",
    "    print(f\"Files to upload: {local_files}\")\n",
    "    await client.upload_files(local_files)\n",
    "\n",
    "    # Step 3: Start the job\n",
    "    job_start_response = await start_job(job_id)\n",
    "    if not job_start_response:\n",
    "        print(\"‚ùå Failed to start job\")\n",
    "        return\n",
    "\n",
    "    # Step 4: Monitor job status\n",
    "    print(\"\\\\n‚è≥ Monitoring job status...\")\n",
    "    attempt = 1\n",
    "    while True:\n",
    "        print(f\"\\\\nStatus check attempt {attempt}\")\n",
    "        job_status = await check_job_status(job_id)\n",
    "        if not job_status:\n",
    "            print(\"‚ùå Failed to get job status\")\n",
    "            break\n",
    "\n",
    "        status = job_status[\"job_state\"]\n",
    "        if status == \"Completed\":\n",
    "            print(\"‚úÖ Job completed successfully!\")\n",
    "            break\n",
    "        elif status == \"Failed\":\n",
    "            print(\"‚ùå Job failed!\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"‚è≥ Current status: {status}\")\n",
    "            await asyncio.sleep(10)\n",
    "        attempt += 1\n",
    "\n",
    "    # Step 5: Download results\n",
    "    if status == \"Completed\":\n",
    "        print(f\"\\nüì• Downloading results from: {output_storage_path}\")\n",
    "        client.update_url(output_storage_path)  # Update URL to the file path\n",
    "\n",
    "        # List all the files you want to download\n",
    "        files = await client.list_files()\n",
    "\n",
    "        # Specify the local destination directory\n",
    "        destination_dir = (\n",
    "            \"/Users/vinayakgavariya/Downloads/\"  # Set this to the local path you want\n",
    "        )\n",
    "\n",
    "        # Make sure the directory exists before downloading\n",
    "        os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "        # Download the files to the local directory\n",
    "        await client.download_files(files, destination_dir=destination_dir)\n",
    "        print(f\"Files have been downloaded to: {destination_dir}\")\n",
    "\n",
    "        print(\"\\\\n=== Processing Complete ===\")\n",
    "\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For files longer than 10 minutes**\n",
    "\n",
    "### **Define the `split_audio` Function**\n",
    "\n",
    "This function splits an audio file into smaller chunks of a specified duration. This is useful for processing long audio files that exceed the API's input length limit.\n",
    "\n",
    "### Note:-\n",
    "Please modify this code according to your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(audio_path, chunk_duration_ms):\n",
    "    \"\"\"\n",
    "    Splits an audio file into smaller chunks of specified duration.\n",
    "\n",
    "    Args:\n",
    "        audio_path (str): Path to the audio file to be split.\n",
    "        chunk_duration_ms (int): Duration of each chunk in milliseconds.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of AudioSegment objects representing the audio chunks.\n",
    "    \"\"\"\n",
    "    audio = AudioSegment.from_file(audio_path)  # Load the audio file\n",
    "    chunks = []\n",
    "    if len(audio) > chunk_duration_ms:\n",
    "        # Split the audio into chunks of the specified duration\n",
    "        for i in range(0, len(audio), chunk_duration_ms):\n",
    "            chunks.append(audio[i : i + chunk_duration_ms])\n",
    "    else:\n",
    "        # If the audio is shorter than the chunk duration, use the entire audio\n",
    "        chunks.append(audio)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_chunks(\n",
    "    audio_file_path, api_url, headers, data, chunk_duration_ms=5 * 60 * 1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Transcribes audio chunks using the Speech-to-Text API.\n",
    "\n",
    "    Args:\n",
    "        audio_file_path (str): Path to the audio file.\n",
    "        api_url (str): The API endpoint URL for Speech-to-Text.\n",
    "        headers (dict): Headers containing authentication information.\n",
    "        data (dict): Data payload for the transcription API.\n",
    "        chunk_duration_ms (int): Duration of each audio chunk in milliseconds.\n",
    "\n",
    "    Returns:\n",
    "        dict: Collated response containing the transcript.\n",
    "    \"\"\"\n",
    "    # Split the audio into chunks\n",
    "    chunks = split_audio(audio_file_path, chunk_duration_ms)\n",
    "    responses = []  # List to store the transcription results\n",
    "\n",
    "    # Process each chunk\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        # Export the chunk to a BytesIO object (in-memory binary stream)\n",
    "        chunk_buffer = io.BytesIO()\n",
    "        chunk.export(chunk_buffer, format=\"wav\")\n",
    "        chunk_buffer.seek(0)  # Reset the pointer to the start of the stream\n",
    "\n",
    "        # Prepare the file for the API request\n",
    "        files = {\"file\": (\"audiofile.wav\", chunk_buffer, \"audio/wav\")}\n",
    "\n",
    "        try:\n",
    "            # Make the POST request to the API\n",
    "            response = requests.post(api_url, headers=headers, files=files, data=data)\n",
    "            if response.status_code == 200 or response.status_code == 201:\n",
    "                print(f\"Chunk {idx} POST Request Successful!\")\n",
    "                response_data = response.json()\n",
    "                transcript = response_data.get(\"transcript\", \"\")\n",
    "                responses.append({\"transcript\": transcript})\n",
    "            else:\n",
    "                # Handle failed requests\n",
    "                print(\n",
    "                    f\"Chunk {idx} POST Request failed with status code: {response.status_code}\"\n",
    "                )\n",
    "                print(\"Response:\", response.text)\n",
    "        except Exception as e:\n",
    "            # Handle any exceptions during the request\n",
    "            print(f\"Error processing chunk {idx}: {e}\")\n",
    "        finally:\n",
    "            # Ensure the buffer is closed after processing\n",
    "            chunk_buffer.close()\n",
    "\n",
    "    # Collate the transcriptions from all chunks\n",
    "    collated_responses = {\n",
    "        \"collated_transcript\": \" \".join([i[\"transcript\"] for i in responses])\n",
    "    }\n",
    "    return collated_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Additional Resources**\n",
    "\n",
    "For more details, refer to the official **Saaras API documentation** and join the community for support:\n",
    "\n",
    "- **Documentation**: [docs.sarvam.ai](https://docs.sarvam.ai/)\n",
    "- **Community**: [Join the Discord Community](https://discord.gg/hTuVuPNF)\n",
    "\n",
    "---\n",
    "\n",
    "## **Final Notes**\n",
    "\n",
    "- Keep your API key secure.\n",
    "- Use clear audio for best results.\n",
    "- Explore advanced features like diarization and word-level timestamps.\n",
    "\n",
    "**Keep Building!** üöÄ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
