{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# **üìñ Speech-to-Text Translation API Using Saaras Model**\n",
    "\n",
    "> Complete STT-Translate tutorial using Sarvam AI's Saaras model. Learn to translate audio directly to English text with automatic language detection and domain prompting.\n",
    "\n",
    "## **üîó Overview**\n",
    "\n",
    "This notebook provides a step-by-step guide on how to use the **STT-Translate API** for translating audio files into text using **Saaras**, this API automatically detects the input language, transcribes the speech, and translates the text to English.\n",
    "\n",
    "It includes instructions for installation, setting up the API key, uploading audio files, and translating audio using the API.\n",
    "\n",
    "### **Instructions to Keep in Mind Before Running the Notebook:**\n",
    "\n",
    "1. **Get the Subscription Key**:  \n",
    "   Go to [dashboard.sarvam.ai](https://dashboard.sarvam.ai) and copy your **API-Subscription Key**.\n",
    "\n",
    "2. **Upload Files**:  \n",
    "   Use the **Upload** button in the Jupyter notebook to upload the files (e.g., audio files) you want to process.\n",
    "\n",
    "3. **Set File Path**:  \n",
    "   Modify the file path in the code to match the path of your uploaded file, e.g., `file_path = '/path/to/your/file.wav'`.\n",
    "\n",
    "4. **Run the Code**:  \n",
    "   Execute the code with the correct **API key** and **file paths**.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55f8538d",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## **1. Installation**\n",
    "\n",
    "Before you begin, ensure you have the necessary Python libraries installed. Run the following commands to install the required packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c84f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sarvamai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbf9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sarvamai import SarvamAI"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## **2. Authentication**\n",
    "\n",
    "To use the API, you need an API subscription key. Follow these steps to set up your API key:\n",
    "\n",
    "1. **Obtain your API key**: If you don't have an API key, sign up on the [Sarvam AI Dashboard](https://dashboard.sarvam.ai/) to get one.\n",
    "2. **Replace the placeholder key**: In the code below, replace \"YOUR_SARVAM_AI_API_KEY\" with your actual API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b8879",
   "metadata": {},
   "outputs": [],
   "source": [
    "SARVAM_API_KEY = \"YOUR_SARVAM_AI_API_KEY\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### **2.1 Initialize the Client**\n",
    "\n",
    "Create a Sarvam client instance using your API key. This client will be used to interact with the Saaras API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dde409",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = SarvamAI(api_subscription_key=SARVAM_API_KEY)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## **3. Uploading Audio Files**\n",
    "\n",
    "To translate audio, you need to provide a `.wav` or `.mp3` file.\n",
    "\n",
    "#### Supported Environments:\n",
    "\n",
    "* Google Colab\n",
    "* Jupyter Notebook (VS Code, JupyterLab, etc.)\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "* Ensure your audio file is in `.wav` **or** `.mp3` format.\n",
    "* Run the cell below. The uploader will automatically adjust based on your environment:\n",
    "  * **In Google Colab**: You'll be prompted to upload a `.wav` or `.mp3` file via a file picker.\n",
    "  * **In Jupyter Notebook**: You'll be prompted to enter the full file path of the `.wav` or `.mp3` file stored locally on your machine.\n",
    "* Once provided, the file will be available for use in the next step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba5ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def get_audio_file():\n",
    "    supported_formats = [\".wav\", \".mp3\"]\n",
    "\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        # Running in Google Colab: use upload widget\n",
    "        from google.colab import files\n",
    "\n",
    "        uploaded = files.upload()\n",
    "        audio_file_path = list(uploaded.keys())[0]\n",
    "        ext = os.path.splitext(audio_file_path)[1].lower()\n",
    "        if ext not in supported_formats:\n",
    "            print(f\"Unsupported file format '{ext}'. Please upload a WAV or MP3 file.\")\n",
    "            return None\n",
    "        print(f\"File '{audio_file_path}' uploaded successfully in Colab!\")\n",
    "        return audio_file_path\n",
    "    else:\n",
    "        # Running in Jupyter Notebook: input file path\n",
    "        audio_file_path = input(\"Enter the path to your MP3 or WAV file: \").strip()\n",
    "        ext = os.path.splitext(audio_file_path)[1].lower()\n",
    "        if not os.path.exists(audio_file_path):\n",
    "            print(f\"File not found at: {audio_file_path}\")\n",
    "            return None\n",
    "        if ext not in supported_formats:\n",
    "            print(f\"Unsupported file format '{ext}'. Please provide a WAV or MP3 file.\")\n",
    "            return None\n",
    "        print(f\"File '{audio_file_path}' found successfully in Jupyter!\")\n",
    "        return audio_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a6c976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the file path and enter/return.\n",
    "audio_file_path = get_audio_file()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## **4. Saaras-v2.5 Usage for STT Translate**\n",
    "\n",
    "The Saaras-v2.5 model is a domain-aware speech translation model that automatically detects the input language and translates to English. It supports code-mixed Indian speech, automatic language detection, and domain-specific prompting.\n",
    "\n",
    "### **API Parameters**\n",
    "\n",
    "| Parameter | Type | Required | Description |\n",
    "|-----------|------|----------|-------------|\n",
    "| `file` | file | Yes | Audio file to translate (WAV, MP3, AAC, FLAC, OGG, etc.) |\n",
    "| `model` | string | Yes | Model version: `saaras:v2.5` |\n",
    "| `prompt` | string | No | Domain-specific prompt to enhance translation accuracy |\n",
    "| `input_audio_codec` | string | No | Required for PCM formats: `pcm_s16le`, `pcm_l16`, `pcm_raw` |\n",
    "\n",
    "### **Supported Input Languages**\n",
    "\n",
    "Saaras supports translation from 11 Indian languages to English:\n",
    "\n",
    "| Language | Code | Language | Code |\n",
    "|----------|------|----------|------|\n",
    "| English | `en-IN` | Hindi | `hi-IN` |\n",
    "| Bengali | `bn-IN` | Tamil | `ta-IN` |\n",
    "| Telugu | `te-IN` | Gujarati | `gu-IN` |\n",
    "| Kannada | `kn-IN` | Malayalam | `ml-IN` |\n",
    "| Marathi | `mr-IN` | Punjabi | `pa-IN` |\n",
    "| Odia | `od-IN` | | |\n",
    "\n",
    "**Note:** Saaras automatically detects the source language - no language code specification needed.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "918a938c",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### **4.1 Basic Usage**\n",
    "\n",
    "Basic transcription with specified language code.  \n",
    "Perfect for single-language content with clear audio quality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79929cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if audio_file_path:\n",
    "    with open(audio_file_path, \"rb\") as audio_file:\n",
    "        response = client.speech_to_text.translate(file=audio_file, model=\"saaras:v2.5\")\n",
    "    print(\"Transcription Response:\")\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"No audio file found. Transcription aborted.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### **4.2 Code-Mixed Speech**\n",
    "\n",
    "Handles mixed-language content with automatic detection of language switches within sentences.  \n",
    "Ideal for natural Indian conversations that mix multiple languages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69f0f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "if audio_file_path:\n",
    "    with open(audio_file_path, \"rb\") as audio_file:\n",
    "        response = client.speech_to_text.translate(file=audio_file, model=\"saaras:v2.5\")\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"No valid audio file found.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### **4.3 Automatic Language Detection**\n",
    "\n",
    "Let Saaras automatically detect the language being spoken.  \n",
    "Useful when the input language is unknown or for handling multi-language content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd24c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "if audio_file_path:\n",
    "    with open(audio_file_path, \"rb\") as audio_file:\n",
    "        response = client.speech_to_text.translate(\n",
    "            file=audio_file,\n",
    "            model=\"saaras:v2.5\",\n",
    "        )\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"No valid audio file found.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### **4.4 Domain Prompting**\n",
    "\n",
    "Enhance transcription accuracy with domain-specific prompts and preserve important terms.  \n",
    "Perfect for specialized contexts like medical, legal, or technical content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "if audio_file_path:\n",
    "    with open(audio_file_path, \"rb\") as audio_file:\n",
    "        response = client.speech_to_text.translate(\n",
    "            file=audio_file, model=\"saaras:v2.5\", prompt=\"Medical consultation\"\n",
    "        )\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"No valid audio file found.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## **5. Handling Long Audio Files**\n",
    "\n",
    "If your audio file exceeds the 30-second limit supported by the **real-time transcription API**, you must split it into smaller chunks for accurate and successful transcription.\n",
    "These smaller segments are then transcribed individually using the **real-time API**, and the results are stitched back together to form the final transcript.\n",
    "\n",
    "üëâ For large audio files, switch to the **Batch API** designed for longer durations.  \n",
    "[üîó Try the Batch API here](https://github.com/sarvamai/sarvam-ai-cookbook/tree/main/notebooks/stt-translate/stt-translate-batch-api)\n",
    "\n",
    "---\n",
    "\n",
    "### When to Use\n",
    "\n",
    "* Audio length >30 seconds\n",
    "* **Real-time API** returns timeout or error due to size\n",
    "* You want to **batch process** long audio files for better accuracy and reliability\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. The full `.mp3` or `.wav` file is first **split into smaller chunks** (e.g., 29 seconds each)\n",
    "2. Each chunk is then transcribed **individually** using the **real-time API**\n",
    "3. The individual results are finally **combined** to form one seamless transcript\n",
    "\n",
    "> ‚ö†Ô∏è For short audio files (<30 seconds), you can skip this step and directly proceed with transcription using the real-time API.\n",
    "\n",
    "The functions below help with:\n",
    "\n",
    "* Prevents real-time API timeouts\n",
    "* Splitting large `.wav`or `.mp3` files into smaller chunks\n",
    "* Transcribing each chunk using the Saaras:v2.5\n",
    "* Collating results into a single transcript\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c76db533",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### **5.1 Define the split_audio Function**\n",
    "\n",
    "This function splits a long `.mp3` or `.wav` audio file into smaller chunks (default: 29 seconds) using **FFmpeg**.\n",
    "It ensures each segment remains within the real-time API's 30-second limit and stores them in the specified output directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6397475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def split_audio_ffmpeg(audio_path, chunk_duration=29, output_dir=\"chunks\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    ext = os.path.splitext(audio_path)[1].lower()\n",
    "    base_name = os.path.splitext(os.path.basename(audio_path))[0]\n",
    "    output_pattern = os.path.join(output_dir, f\"{base_name}_%03d{ext}\")\n",
    "\n",
    "    codec = \"pcm_s16le\" if ext == \".wav\" else \"libmp3lame\"\n",
    "\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\",\n",
    "        audio_path,\n",
    "        \"-f\",\n",
    "        \"segment\",\n",
    "        \"-segment_time\",\n",
    "        str(chunk_duration),\n",
    "        \"-c:a\",\n",
    "        codec,\n",
    "        output_pattern,\n",
    "    ]\n",
    "\n",
    "    print(\"Running command:\", \" \".join(command))\n",
    "\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    print(\"Return code:\", result.returncode)\n",
    "    print(\"STDOUT:\\n\", result.stdout)\n",
    "    print(\"STDERR:\\n\", result.stderr)\n",
    "\n",
    "    output_files = sorted(\n",
    "        [os.path.join(output_dir, f) for f in os.listdir(output_dir) if f.endswith(ext)]\n",
    "    )\n",
    "\n",
    "    print(\"Chunks generated:\", output_files)\n",
    "    return output_files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### **5.2 Define the `translate_audio_chunks` Function**\n",
    "\n",
    "This function takes the list of chunked audio file paths and uses the **Saaras real-time API** to translate each one individually.\n",
    "It collects all partial transcriptions and combines them into a single, complete transcript.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_audio_chunks(chunk_paths, client, model=\"saaras:v2.5\"):\n",
    "\n",
    "    full_transcript = []\n",
    "\n",
    "    for idx, chunk_path in enumerate(chunk_paths):\n",
    "        print(f\"\\nTranslating chunk {idx + 1}/{len(chunk_paths)} ‚Üí {chunk_path}\")\n",
    "        with open(chunk_path, \"rb\") as audio_file:\n",
    "            try:\n",
    "                response = client.speech_to_text.translate(file=audio_file, model=model)\n",
    "                print(\"Chunk Response:\", response)\n",
    "                full_transcript.append(str(response))\n",
    "            except Exception as e:\n",
    "                print(f\"Error with chunk {chunk_path}: {e}\")\n",
    "\n",
    "    return \" \".join(full_transcript).strip()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "162d0432",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### **5.3 Putting It All Together**\n",
    "\n",
    "Call the `split_audio_ffmpeg()` function first to break the audio into chunks, and then pass those chunks to `translate_audio_chunks()` for transcription.\n",
    "This two-step process ensures large audio files are handled smoothly using the real-time API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split the audio\n",
    "chunks = split_audio_ffmpeg(audio_file_path)\n",
    "\n",
    "# 2. Translate each chunk and collate\n",
    "if chunks:\n",
    "    final_transcript = translate_audio_chunks(chunks, client)\n",
    "    print(\"\\nFinal Combined Transcript:\\n\")\n",
    "    print(final_transcript)\n",
    "else:\n",
    "    print(\"No audio chunks generated. Transcription aborted.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13dbcfb9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e2420cc2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d7fad02-a800-40e5-a2e5-0abfd9ceb869",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vvf7s2t8H3EO",
   "metadata": {
    "id": "Vvf7s2t8H3EO"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OvZ0-mhCoN8-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OvZ0-mhCoN8-",
    "outputId": "1a5cdb38-64f4-418e-9217-a2e5fcc85c23"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05cab7-d20f-4fcb-9e34-0b6e65aa1341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Eqdfvakn8Kw_",
   "metadata": {
    "id": "Eqdfvakn8Kw_"
   },
   "source": [
    "## **2. Authentication**\n",
    "\n",
    "To use the API, you need an API subscription key. Follow these steps to set up your API key:\n",
    "\n",
    "1. **Obtain your API key**: If you don‚Äôt have an API key, sign up on the [Sarvam AI Dashboard](https://dashboard.sarvam.ai/) to get one.\n",
    "2. **Replace the placeholder key**: In the code below, replace \"YOUR_SARVAM_AI_API_KEY\" with your actual API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kp_kAaY0dtA9",
   "metadata": {
    "id": "Kp_kAaY0dtA9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffb9dbd1-e436-4e15-b329-7c995d982eeb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da45d08f-22d3-4e4d-bc34-72fca758a394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "qaC3-oLTeZ8T",
   "metadata": {
    "id": "qaC3-oLTeZ8T"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ekiIlxBeeV5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "9ekiIlxBeeV5",
    "outputId": "9691235e-ec4d-4c27-ed1e-cae6714c3138"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a202e-bcb2-4916-b8bd-feb0202fd7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d563915-d247-4644-882c-33a4c2222410",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QeFprHO1uSrV",
   "metadata": {
    "id": "QeFprHO1uSrV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f0d05d5-7f36-447b-ac86-b00ebdebe0b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca52184-0f88-4781-b9dc-cd9c6dedee22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c2dbfaa-c3b1-4244-bdb5-00be0567cc78",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432bb2da-0be8-490e-a362-e79ba8d9bbb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05b8f5d7-5e8b-4b78-a0d3-583512c66ac5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4145d96-1699-43cd-9696-4b4523167460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1743020a-29f8-4079-82e3-9ff33025af81",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f95e2e-81b4-423f-b440-0d21cc5a955f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc8bd47-a639-45ca-ad57-57ceead7ccc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bm0pktY98Ccs",
   "metadata": {
    "id": "bm0pktY98Ccs"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e77042-7c1b-4dd5-b050-73a9054aa005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7CorqAF18cZF",
   "metadata": {
    "id": "7CorqAF18cZF"
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b0294a-ca81-468b-993f-09fca5c5b2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dec003c2-3282-4da1-a8e7-fa5a16629cab",
   "metadata": {},
   "source": [
    "## **6. Error Handling**  \n",
    "\n",
    "You may encounter these errors while using the API:  \n",
    "\n",
    "| Error Code | HTTP Status | Cause | Solution |\n",
    "|------------|-------------|-------|----------|\n",
    "| `invalid_api_key_error` | 403 Forbidden | Invalid API key | Use a valid API key from the [Sarvam AI Dashboard](https://dashboard.sarvam.ai/) |\n",
    "| `insufficient_quota_error` | 429 Too Many Requests | Exceeded API quota | Check your usage, upgrade if needed, or implement exponential backoff |\n",
    "| `internal_server_error` | 500 Internal Server Error | Issue on servers | Try again later. If persistent, contact support |\n",
    "| `invalid_request_error` | 400 Bad Request | Incorrect request formatting | Verify your request structure and parameters |\n",
    "| `rate_limit_exceeded_error` | 429 Too Many Requests | Rate limit exceeded | Implement rate limiting and retry with backoff |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a67e5d-d63d-46a9-8477-09be7edf9581",
   "metadata": {},
   "source": [
    "## **7. Additional Resources**\n",
    "\n",
    "For more details, refer to the our official documentation and we are always there to support and help you on our Discord Server:\n",
    "\n",
    "- **Documentation**: [docs.sarvam.ai](https://docs.sarvam.ai)  \n",
    "- **Community**: [Join the Discord Community](https://discord.gg/hTuVuPNF)\n",
    "\n",
    "## **8. Final Notes**\n",
    "\n",
    "- Keep your API key secure.\n",
    "- Use clear audio for best results.\n",
    "- Saaras automatically detects the input language and translates to English.\n",
    "- Use the `prompt` parameter for domain-specific translations (e.g., medical, legal).\n",
    "\n",
    "**Keep Building!** üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yTl30sXzqXjv",
   "metadata": {
    "id": "yTl30sXzqXjv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
